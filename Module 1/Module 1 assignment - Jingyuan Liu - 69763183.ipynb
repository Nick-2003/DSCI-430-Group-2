{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f416c434",
   "metadata": {},
   "source": [
    "# DSCI 430 - Fairness, Accountability, Transparency and Ethics (FATE) in Data Science\n",
    "\n",
    "# Module 1 - Introduction and Ethical foundations \n",
    "\n",
    "\n",
    "\n",
    "### Assignment overview\n",
    "\n",
    "This assignment is composed of three parts:\n",
    "- **Part 1 - The Black Mirror Writers' Room.** In this portion of the exercise, you will brainstorm near future technology and its possible drawbacks, and illustrate them in a futuristic cautionary tale. You will also be asked questions about ethical theories and how they apply to the scenario you have described. Credits: [Casey Fiesler - The Black Mirror Writers Room: The Case (and Caution) for Ethical Speculation in CS Education](https://medium.com/cuinfoscience/the-black-mirror-writers-room-the-case-and-caution-for-ethical-speculation-in-cs-education-5c81d05d2c67)\n",
    "- **Part 2 - Python review.** As this course uses Python as the programming language for our exercises, a basic understanding of the fundamentals and the use of some libraries is necessary. This portion of the exercise will help you review useful Python syntax and/or fill the gap in your knowledge before tackling larger exercises. We recommend discussing with an instructor if you find this portion of the assignment too difficult to complete with a reasonable amount of effort.\n",
    "- **Part 3 - Final thoughts.** Complete this section so that we can better understand how you completed the assignment and any issues you may have encountered.\n",
    "\n",
    "For this assignment, it is possible to work in **groups of up to 2 students**. Read the instructions carefully, as they may assign tasks to specific students.\n",
    "\n",
    "### Group members\n",
    "Leave Student 2 blank if group has less than 2 members:\n",
    "- Student 1: Jingyuan Liu 69763183\n",
    "- Student 2: Nicholas Tam 45695970\n",
    "\n",
    "### Learning Goals:\n",
    "\n",
    "After completing this week's lecture and tutorial work, you will be able to:\n",
    "1. Define ethics and describe what constitutes an ethical issue \n",
    "2. Explain the need for ethics in data science  \n",
    "3. Identify common ethical issues in data science  \n",
    "4. Describe common ethical frameworks and how they can be applied to data science applications \n",
    "5. Imagine scenarios in which current technology could be used in unethical ways \n",
    "6. Evaluate and make arguments around data science scenarios using ethical theories (e.g., Kantianism, utilitarianism, virtue ethics etc.)  \n",
    "7. Compare and contrast different ethical theories and explain the case for and against each one as they apply to data science\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9522ae92",
   "metadata": {},
   "source": [
    "# The Black Mirror Writers' Room\n",
    "\n",
    "Black Mirror is a Netflix series centered around the use of advanced technology and its possible unexpected (sometimes catastrophic) consequences. In this exercise, you will come up with your very own Black Mirror episode (or at least a synopsis)! \n",
    "\n",
    "## Warm up\n",
    "\n",
    "Before jumping into the creative writing part, we should review the various elements of FATE in Data Science and make sure that they are clear:\n",
    "\n",
    "| FATE element    | Definition |\n",
    "| :-------- | :------- |\n",
    "| **Fairness**  | The idea that every group or population that is affected by a technological application is being treated equally and not receiving a different outcome *solely because they belong to their group*.   |\n",
    "| **Accountability** | Clear definition of who should be held responsible of the outcome of the technological application and under what circumstances. |\n",
    "| **Transparency** | The technical definition of transparency in Data Science refers to being able to understand why a technological application produced a specific outcome. This is also called *explainability*. But transparency can also refer to the demand of making the use of algorithms more transparent to the public, including informing the users about when they are used, where the data used was sourced from, and making algorithms available for auditing.|\n",
    "| **Ethics** | Evaluation of whether or not a technology should be used based on the moral values of a group or society. Society may reject a technology because it is does not follow the principles of Fairness, Accountability or Transparency, but also for other reasons.|\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Consider the following scenario:\n",
    "\n",
    "In the country of Dataland, the police department uses an algorithm to assess the risk level of people reporting cases of domestic abuses and violence. Thanks to this algorithm, they can identify the most serious threats and intervene accordingly. The algorithm has had a positive impact, assessing cases with more accuracy than other prior strategies and allowing the police force to make an efficient use of their resources. However, it occasionally fails to correctly identify people at high risk of violence (*false negatives*), leaving them without the protection they need. It is also affected by other issues. For each issue outlined in this table, check whether it is a Fairness, Accountability or Transparency problem.\n",
    "\n",
    "| Issue    | Fairness | Accountability | Transparency |\n",
    "| :-------- | :------- | :------- | :------- |\n",
    "| When the algorithm fails to identify a high-risk case and violence occurs, it is unclear if the police department should shoulder any responsibility. |        |        |        | \n",
    "| An analysis of the algorithm's results suggests that false negatives occur more frequently among victims with physical disabilities. |        |        |        | \n",
    "| The majority of people reporting domestic abuse are not aware that their cases are being evaluated by an algorithm, or do not know the score they received. |        |        |        | \n",
    "| The police department receives a recommendation for each case, but does not know which characteristic(s) of the case have resulted in the final evaluation. |        |        |        | \n",
    "| The algorithm was trained using past cases filed by the police department, but the people involved where not informed that their information was being used for this purpose. |        |        |        | \n",
    "\n",
    "### Question 2\n",
    "\n",
    "Considere the issues outlined in the previous question, as well as the fact that the algorithm is the best system of appraisal available to the police forces so far for cases of domestic violence. Do you think that the use of this algorithm is *ethical*? Clearly state your thesis (opposed/favourable) and use one of the ethical perspectives listed in [this reading](https://www.scu.edu/ethics-in-technology-practice/ethical-lenses/) to support it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d70f1",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c719b",
   "metadata": {},
   "source": [
    "**Note:** this case is fictional but inspired by a real algorithm, called VioGÃ©n, used in Spain to determine the risk level of victims of gender-based violence and assign protection measures. The algorithm has been recently going under severe scrutiny [(Read more).](https://eticas.ai/the-adversarial-audit-of-viogen-three-years-later/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716871c",
   "metadata": {},
   "source": [
    "### Question 3: Write your own Black Mirror episode\n",
    "\n",
    "Now that you have acquired the necessary familiarity with some required knowledge and terminology, it is time to use your creativity!\n",
    "\n",
    "**Step 1:** Brainstorm *one* near future technology based on a topic of your choice. It should be close enough that it seems like a plausible future. Describe it in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422e4c9",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915ce50",
   "metadata": {},
   "source": [
    "**Step 2:** What are the potential social implications and/or ethical issues and/or regulatory challenges with this technology? Explain if and how they are connected to FATE (e.g. is it a Fairness issue? Or maybe a Transparency issue? It could be more than one option)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24479bf",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbecd0e0",
   "metadata": {},
   "source": [
    "**Step 3:** Time for storytelling! Write the summary of a new Black Mirror episode based on the technology of your choice. Try covering all of the following:\n",
    "\n",
    "- What do you think might be a cautionary tale related to this technology? \n",
    "- What fictional person in the future would best illustrate this caution? Provide a detailed description and explain what makes them the best character to carry your message.\n",
    "- What is their story? Explain their background, their motivations, and their journey through your episode.\n",
    "\n",
    "As part of your submission, please update the episode thumbnail slide (from Module 1 slide deck) using information from your episode. Don't forget to add a picture! Then, share it with the rest of the class on [Canvas](https://canvas.ubc.ca/courses/134264/discussion_topics/1943920).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b3d7b",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c018b",
   "metadata": {},
   "source": [
    "**Step 4:** Let's take a step back, and imagine that you are (one of) an activist/legistlator/technology practitioner at the time the technology described in your episode is being developed and its use being discussed. Select *one* of the ethical perspectives listed in [this reading](https://www.scu.edu/ethics-in-technology-practice/ethical-lenses/), and use this perspective to argue against its deployment. Pay particular attention to the counter-arguments! People with interests in this technology will certainly argue against you, and you must anticipate and rebut their claims. Include at least 2 conter-arguments and how you would respond to them.\n",
    "\n",
    "**Ethical perspective chosen:** \n",
    "\n",
    "**Argument:**\n",
    "\n",
    "**First counter-argument (with rebuttal):**\n",
    "\n",
    "**Second counter-argument (with rebuttal):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a531a70",
   "metadata": {},
   "source": [
    "**Step 5:** Finally, let's end on a more positive note and imagine a \"Light Mirror\" scenario, where the negative consequences of the technology you have described are averted and positive results are achieved in their stead. Try answering the following questions:\n",
    "\n",
    "1. What kinds of solutions can be deployed in the immediate for addressing the harms of the technology you have described? What could we do to ensure that we donât get to the negative consequences you imagined later in the future?\n",
    "2. Could you imagine a scenario where the technology you have described is used with positive consequences, given the appropriate safe guards? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa8a9e",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44908a97",
   "metadata": {},
   "source": [
    "### Sources\n",
    "The Black Mirror Writers' Room exercises was designed by [Dr. Casey Fiesler](https://caseyfiesler.com/). Links to her work and publications:\n",
    "- [The Black Mirror Writers Room: The Case (and Caution) for Ethical Speculation in CS Education](https://medium.com/cuinfoscience/the-black-mirror-writers-room-the-case-and-caution-for-ethical-speculation-in-cs-education-5c81d05d2c67)\n",
    "- [\"Run Wild a Little With Your Imagination\": Ethical Speculation in Computing Education with Black Mirror](https://dl.acm.org/doi/abs/10.1145/3478431.3499308)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2f627",
   "metadata": {},
   "source": [
    "# Python Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a4f514",
   "metadata": {},
   "source": [
    "In this section of the assignment, we will review useful Python functions and libraries that will allow you to read and analyze data, as well as training simple Machine Learning models. \n",
    "\n",
    "## Section 1: Exploring datasets with Pandas\n",
    "\n",
    "First, we will need a dataset to work on. Let's use a [weather type dataset](https://www.kaggle.com/datasets/nikhil7280/weather-type-classification), a good starting dataset (we will save more interesting cases for later!). Download this dataset from the link to use it for this exercise.\n",
    "\n",
    "We also need to import the necessary library to read and manipulate our dataset, which is [Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html). The imports are given to you. Next, use the `read_csv()` function to import the data in your workspace. The documentation for this function can be found [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cc57bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Precipitation (%)</th>\n",
       "      <th>Cloud Cover</th>\n",
       "      <th>Atmospheric Pressure</th>\n",
       "      <th>UV Index</th>\n",
       "      <th>Season</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Location</th>\n",
       "      <th>Weather Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>73</td>\n",
       "      <td>9.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>1010.82</td>\n",
       "      <td>2</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3.5</td>\n",
       "      <td>inland</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.0</td>\n",
       "      <td>96</td>\n",
       "      <td>8.5</td>\n",
       "      <td>71.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>1011.43</td>\n",
       "      <td>7</td>\n",
       "      <td>Spring</td>\n",
       "      <td>10.0</td>\n",
       "      <td>inland</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>64</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>1018.72</td>\n",
       "      <td>5</td>\n",
       "      <td>Spring</td>\n",
       "      <td>5.5</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>83</td>\n",
       "      <td>1.5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>1026.25</td>\n",
       "      <td>7</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>coastal</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.0</td>\n",
       "      <td>74</td>\n",
       "      <td>17.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>overcast</td>\n",
       "      <td>990.67</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.5</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Wind Speed  Precipitation (%)    Cloud Cover  \\\n",
       "0         14.0        73         9.5               82.0  partly cloudy   \n",
       "1         39.0        96         8.5               71.0  partly cloudy   \n",
       "2         30.0        64         7.0               16.0          clear   \n",
       "3         38.0        83         1.5               82.0          clear   \n",
       "4         27.0        74        17.0               66.0       overcast   \n",
       "\n",
       "   Atmospheric Pressure  UV Index  Season  Visibility (km)  Location  \\\n",
       "0               1010.82         2  Winter              3.5    inland   \n",
       "1               1011.43         7  Spring             10.0    inland   \n",
       "2               1018.72         5  Spring              5.5  mountain   \n",
       "3               1026.25         7  Spring              1.0   coastal   \n",
       "4                990.67         1  Winter              2.5  mountain   \n",
       "\n",
       "  Weather Type  \n",
       "0        Rainy  \n",
       "1       Cloudy  \n",
       "2        Sunny  \n",
       "3        Sunny  \n",
       "4        Rainy  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "weather_classification_data = pd.read_csv(\"weather_classification_data.csv\")\n",
    "weather_classification_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59a2ab",
   "metadata": {},
   "source": [
    "Now, let's use the [`describe()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) function of the Pandas library to get an overview of the dataset, and answer the following questions (you can write your answers in this box):\n",
    "\n",
    "- What is the maximum temperature recorded in the dataset? *109*\n",
    "- What is the average wind speed? *9.832197*\n",
    "\n",
    "Note: some of the values you will see may appear unrealistic (such as incredibly high temperatures). The dataset is artificially generated and purposefully includes outliers to practice detection and handling, but it is not something we will worry about it this exercise - we are just interested in getting some practice with useful commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3ab972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Precipitation (%)</th>\n",
       "      <th>Atmospheric Pressure</th>\n",
       "      <th>UV Index</th>\n",
       "      <th>Visibility (km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13200.000000</td>\n",
       "      <td>13200.000000</td>\n",
       "      <td>13200.000000</td>\n",
       "      <td>13200.000000</td>\n",
       "      <td>13200.000000</td>\n",
       "      <td>13200.000000</td>\n",
       "      <td>13200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.127576</td>\n",
       "      <td>68.710833</td>\n",
       "      <td>9.832197</td>\n",
       "      <td>53.644394</td>\n",
       "      <td>1005.827896</td>\n",
       "      <td>4.005758</td>\n",
       "      <td>5.462917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.386327</td>\n",
       "      <td>20.194248</td>\n",
       "      <td>6.908704</td>\n",
       "      <td>31.946541</td>\n",
       "      <td>37.199589</td>\n",
       "      <td>3.856600</td>\n",
       "      <td>3.371499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>800.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>994.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>1007.650000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>1016.772500</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>1199.210000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Temperature      Humidity    Wind Speed  Precipitation (%)  \\\n",
       "count  13200.000000  13200.000000  13200.000000       13200.000000   \n",
       "mean      19.127576     68.710833      9.832197          53.644394   \n",
       "std       17.386327     20.194248      6.908704          31.946541   \n",
       "min      -25.000000     20.000000      0.000000           0.000000   \n",
       "25%        4.000000     57.000000      5.000000          19.000000   \n",
       "50%       21.000000     70.000000      9.000000          58.000000   \n",
       "75%       31.000000     84.000000     13.500000          82.000000   \n",
       "max      109.000000    109.000000     48.500000         109.000000   \n",
       "\n",
       "       Atmospheric Pressure      UV Index  Visibility (km)  \n",
       "count          13200.000000  13200.000000     13200.000000  \n",
       "mean            1005.827896      4.005758         5.462917  \n",
       "std               37.199589      3.856600         3.371499  \n",
       "min              800.120000      0.000000         0.000000  \n",
       "25%              994.800000      1.000000         3.000000  \n",
       "50%             1007.650000      3.000000         5.000000  \n",
       "75%             1016.772500      7.000000         7.500000  \n",
       "max             1199.210000     14.000000        20.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_classification_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a985c0a8",
   "metadata": {},
   "source": [
    "The `describe()` function is helpful, but it does not answer all the questions we may have. For example, we did not get any idea about the class distribution in our dataset, that is, how many samples we have for each of the four classes (Rainy, Cloudy, Sunny, Snowy). Can you write a line of code to answer this question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a752e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weather Type\n",
       "Rainy     3300\n",
       "Cloudy    3300\n",
       "Sunny     3300\n",
       "Snowy     3300\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_classification_data['Weather Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ababd",
   "metadata": {},
   "source": [
    "Thanks to `describe()`, we know that the minimum temperature recorded is -25 C, but we have no idea which sample it belongs to. Can you write a line of code to find the sample number and also the Weather Type associated to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3480f1df-c57e-4401-830c-d8efb2ee4288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Precipitation (%)</th>\n",
       "      <th>Cloud Cover</th>\n",
       "      <th>Atmospheric Pressure</th>\n",
       "      <th>UV Index</th>\n",
       "      <th>Season</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Location</th>\n",
       "      <th>Weather Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>-25.0</td>\n",
       "      <td>105</td>\n",
       "      <td>29.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>overcast</td>\n",
       "      <td>980.86</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.5</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Snowy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature  Humidity  Wind Speed  Precipitation (%) Cloud Cover  \\\n",
       "4609        -25.0       105        29.0              106.0    overcast   \n",
       "\n",
       "      Atmospheric Pressure  UV Index  Season  Visibility (km)  Location  \\\n",
       "4609                980.86         1  Winter              2.5  mountain   \n",
       "\n",
       "     Weather Type  \n",
       "4609        Snowy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_classification_data.loc[weather_classification_data['Temperature'] == \n",
    "                                weather_classification_data['Temperature'].min()]\n",
    "\n",
    "## The sample index number is 4609 and its weather type is snowy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346446a",
   "metadata": {},
   "source": [
    "Again thanks to `describe()`, we know that 25% of the samples in the dataset have a recorded Precipitation higher that 82 (you can verify this in the output table), but how many of these are Snowy? Answer this question in 1 line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebea834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1243, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_classification_data.loc[(weather_classification_data['Precipitation (%)'] > 82) & \n",
    "                                (weather_classification_data['Weather Type'] == \"Snowy\")].shape\n",
    "\n",
    "## 1243 of those with a recorded Precipitation higher than 82 are snowy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75a00a",
   "metadata": {},
   "source": [
    "Finally, sometimes we may be interested in sorting the dataframe by the values in a column. In this cell, sort the dataframe by humidity in descending order, and check the results by printing the first 5 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07aaa619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Precipitation (%)</th>\n",
       "      <th>Cloud Cover</th>\n",
       "      <th>Atmospheric Pressure</th>\n",
       "      <th>UV Index</th>\n",
       "      <th>Season</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Location</th>\n",
       "      <th>Weather Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>52.0</td>\n",
       "      <td>109</td>\n",
       "      <td>22.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>overcast</td>\n",
       "      <td>1013.40</td>\n",
       "      <td>9</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11347</th>\n",
       "      <td>-11.0</td>\n",
       "      <td>109</td>\n",
       "      <td>31.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>overcast</td>\n",
       "      <td>994.98</td>\n",
       "      <td>14</td>\n",
       "      <td>Winter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mountain</td>\n",
       "      <td>Snowy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9901</th>\n",
       "      <td>49.0</td>\n",
       "      <td>109</td>\n",
       "      <td>23.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>overcast</td>\n",
       "      <td>1003.42</td>\n",
       "      <td>8</td>\n",
       "      <td>Winter</td>\n",
       "      <td>5.5</td>\n",
       "      <td>coastal</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>57.0</td>\n",
       "      <td>109</td>\n",
       "      <td>13.5</td>\n",
       "      <td>109.0</td>\n",
       "      <td>overcast</td>\n",
       "      <td>999.40</td>\n",
       "      <td>4</td>\n",
       "      <td>Summer</td>\n",
       "      <td>4.0</td>\n",
       "      <td>inland</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>29.0</td>\n",
       "      <td>109</td>\n",
       "      <td>21.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>1018.98</td>\n",
       "      <td>9</td>\n",
       "      <td>Winter</td>\n",
       "      <td>7.5</td>\n",
       "      <td>inland</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature  Humidity  Wind Speed  Precipitation (%)    Cloud Cover  \\\n",
       "3885          52.0       109        22.5               89.0       overcast   \n",
       "11347        -11.0       109        31.5               95.0       overcast   \n",
       "9901          49.0       109        23.5              100.0       overcast   \n",
       "1204          57.0       109        13.5              109.0       overcast   \n",
       "1303          29.0       109        21.0               93.0  partly cloudy   \n",
       "\n",
       "       Atmospheric Pressure  UV Index  Season  Visibility (km)  Location  \\\n",
       "3885                1013.40         9  Summer              2.0  mountain   \n",
       "11347                994.98        14  Winter              1.0  mountain   \n",
       "9901                1003.42         8  Winter              5.5   coastal   \n",
       "1204                 999.40         4  Summer              4.0    inland   \n",
       "1303                1018.98         9  Winter              7.5    inland   \n",
       "\n",
       "      Weather Type  \n",
       "3885        Cloudy  \n",
       "11347        Snowy  \n",
       "9901        Cloudy  \n",
       "1204         Rainy  \n",
       "1303        Cloudy  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data_by_humidity = weather_classification_data.sort_values(by=\"Humidity\", ascending=False)\n",
    "weather_data_by_humidity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f01f7e",
   "metadata": {},
   "source": [
    "As last step of this section, save the sorted dataframe in a new csv file called \"weather_data_by_humidity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c81a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_by_humidity.to_csv('weather_data_by_humidity.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097333c3",
   "metadata": {},
   "source": [
    "## Section 2: Training ML models with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b407cb",
   "metadata": {},
   "source": [
    "We are now interested in creating a model to predict the weather type based on the features available. Let's see how to do that using the python library [Scikit-learn](https://scikit-learn.org/stable/), while reviewing some important concepts about training and evaluating models. Simply run the cells below to see the output and answer the related questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cefd1",
   "metadata": {},
   "source": [
    "First, we need to split our data set into training and testing set. The next cell shows how to do that. We will also separate the Weather Type column (target) from the other columns (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9133334b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Precipitation (%)</th>\n",
       "      <th>Cloud Cover</th>\n",
       "      <th>Atmospheric Pressure</th>\n",
       "      <th>UV Index</th>\n",
       "      <th>Season</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12987</th>\n",
       "      <td>26.0</td>\n",
       "      <td>45</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>1011.01</td>\n",
       "      <td>7</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>5.0</td>\n",
       "      <td>inland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>29.0</td>\n",
       "      <td>71</td>\n",
       "      <td>21.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>1013.77</td>\n",
       "      <td>12</td>\n",
       "      <td>Winter</td>\n",
       "      <td>6.5</td>\n",
       "      <td>inland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5590</th>\n",
       "      <td>38.0</td>\n",
       "      <td>63</td>\n",
       "      <td>5.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>1013.87</td>\n",
       "      <td>11</td>\n",
       "      <td>Spring</td>\n",
       "      <td>7.5</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>17.0</td>\n",
       "      <td>66</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>992.22</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.5</td>\n",
       "      <td>inland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>32.0</td>\n",
       "      <td>39</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>1021.43</td>\n",
       "      <td>9</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>5.5</td>\n",
       "      <td>inland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature  Humidity  Wind Speed  Precipitation (%)    Cloud Cover  \\\n",
       "12987         26.0        45         3.5               10.0          clear   \n",
       "905           29.0        71        21.0               86.0  partly cloudy   \n",
       "5590          38.0        63         5.5               11.0          clear   \n",
       "7269          17.0        66        18.0               63.0  partly cloudy   \n",
       "1417          32.0        39         7.5                3.0          clear   \n",
       "\n",
       "       Atmospheric Pressure  UV Index  Season  Visibility (km)  Location  \n",
       "12987               1011.01         7  Autumn              5.0    inland  \n",
       "905                 1013.77        12  Winter              6.5    inland  \n",
       "5590                1013.87        11  Spring              7.5  mountain  \n",
       "7269                 992.22         1  Winter              2.5    inland  \n",
       "1417                1021.43         9  Autumn              5.5    inland  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(weather_classification_data, test_size=0.2, random_state=123)  # 80%-20% train test split on df\n",
    "\n",
    "X_train, y_train = train_df.drop(columns=[\"Weather Type\"]), train_df[\"Weather Type\"]\n",
    "X_test, y_test = test_df.drop(columns=[\"Weather Type\"]), test_df[\"Weather Type\"]\n",
    "\n",
    "X_train.head()  # quick visual check on X_train, the features dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91b843",
   "metadata": {},
   "source": [
    "**Question for you:** creating a testing set is very important when training a model. **Why? How is it used? What would happen if we did not do this very important step?** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab435e4",
   "metadata": {},
   "source": [
    "* ### <span style=\"color:red\"> After training the model on the training set, we need to evaluate and assess the performance of the model on an unseen dataset. Since we fit the model on the training set, it is inappropriate to evaluate the model performance on the training set again because the model has seen the datatset before, which will cause the issue of \"overfitting\". The testing set gives the model unseen data and lets the model perform on this new data.  </span>\n",
    "* ### <span style=\"color:red\"> After the original dataset is split into two sets and the model is fitted, we will use the model to predict the targets of observations in the training set given their features in `X_test`. Then the predictive values can be used to compare with the true targets in the testing set `y_test` and then apply some formulas or metrics to evaluate the performance of this model. </span>\n",
    "* ### <span style=\"color:red\"> If we do not have a testing set, we are not able to properly evaluate the performance of the model when it sees new data. We might overestimate the performance because the model usually did a good job on the dataset that was trained on, but it might overfit the training data, causing it perform poorly on an unseen dataset in the future.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432cf61e",
   "metadata": {},
   "source": [
    "As you can see, the dataset includes categorical features. Most classifiers require categorical features to be transformed before they can be used for training and prediction. The code below uses [One Hot Encoding](https://www.geeksforgeeks.org/ml-one-hot-encoding/) to convert the categorical features Cloud Cover, Season and Location, while leaving the numberical features unchanged.\n",
    "\n",
    "This is a simple example of data preprocessing. Preprocessing can be more extensive (for example, including [scaling of numerical features](https://www.geeksforgeeks.org/ml-feature-scaling-part-2/)), but we are only interested in an overview of the fundamentals, so we will just apply One Hot Encoding to make the data usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e61d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "passthrough = ['Temperature', 'Humidity', 'Wind Speed', 'Precipitation (%)', \n",
    "               'Atmospheric Pressure', 'UV Index', 'Visibility (km)']\n",
    "categorical = ['Cloud Cover', 'Season', 'Location']\n",
    "\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical),  # OHE on categorical features\n",
    "    (\"passthrough\", passthrough),  # no transformations on the numberical features\n",
    ")\n",
    "\n",
    "# Fit the encoder on the training data and transform\n",
    "train_encoded = ct.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "test_encoded = ct.transform(X_test)\n",
    "\n",
    "# Convert the encoded data back to DataFrame for better readability\n",
    "\n",
    "column_names = (\n",
    "    ct.named_transformers_[\"onehotencoder\"].get_feature_names_out().tolist() + passthrough\n",
    ")\n",
    "\n",
    "X_train_encoded = pd.DataFrame(train_encoded, columns=column_names)\n",
    "X_test_encoded = pd.DataFrame(test_encoded, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a98bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cloud Cover_clear</th>\n",
       "      <th>Cloud Cover_cloudy</th>\n",
       "      <th>Cloud Cover_overcast</th>\n",
       "      <th>Cloud Cover_partly cloudy</th>\n",
       "      <th>Season_Autumn</th>\n",
       "      <th>Season_Spring</th>\n",
       "      <th>Season_Summer</th>\n",
       "      <th>Season_Winter</th>\n",
       "      <th>Location_coastal</th>\n",
       "      <th>Location_inland</th>\n",
       "      <th>Location_mountain</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Precipitation (%)</th>\n",
       "      <th>Atmospheric Pressure</th>\n",
       "      <th>UV Index</th>\n",
       "      <th>Visibility (km)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1011.01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1013.77</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1013.87</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>992.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1021.43</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>929.72</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1016.64</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10557</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1014.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10558</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1018.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1008.30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10560 rows Ã 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cloud Cover_clear  Cloud Cover_cloudy  Cloud Cover_overcast  \\\n",
       "0                    1.0                 0.0                   0.0   \n",
       "1                    0.0                 0.0                   0.0   \n",
       "2                    1.0                 0.0                   0.0   \n",
       "3                    0.0                 0.0                   0.0   \n",
       "4                    1.0                 0.0                   0.0   \n",
       "...                  ...                 ...                   ...   \n",
       "10555                0.0                 0.0                   0.0   \n",
       "10556                0.0                 0.0                   1.0   \n",
       "10557                1.0                 0.0                   0.0   \n",
       "10558                1.0                 0.0                   0.0   \n",
       "10559                0.0                 0.0                   0.0   \n",
       "\n",
       "       Cloud Cover_partly cloudy  Season_Autumn  Season_Spring  Season_Summer  \\\n",
       "0                            0.0            1.0            0.0            0.0   \n",
       "1                            1.0            0.0            0.0            0.0   \n",
       "2                            0.0            0.0            1.0            0.0   \n",
       "3                            1.0            0.0            0.0            0.0   \n",
       "4                            0.0            1.0            0.0            0.0   \n",
       "...                          ...            ...            ...            ...   \n",
       "10555                        1.0            0.0            1.0            0.0   \n",
       "10556                        0.0            0.0            0.0            1.0   \n",
       "10557                        0.0            0.0            0.0            1.0   \n",
       "10558                        0.0            0.0            0.0            1.0   \n",
       "10559                        1.0            0.0            0.0            1.0   \n",
       "\n",
       "       Season_Winter  Location_coastal  Location_inland  Location_mountain  \\\n",
       "0                0.0               0.0              1.0                0.0   \n",
       "1                1.0               0.0              1.0                0.0   \n",
       "2                0.0               0.0              0.0                1.0   \n",
       "3                1.0               0.0              1.0                0.0   \n",
       "4                0.0               0.0              1.0                0.0   \n",
       "...              ...               ...              ...                ...   \n",
       "10555            0.0               0.0              1.0                0.0   \n",
       "10556            0.0               0.0              0.0                1.0   \n",
       "10557            0.0               0.0              1.0                0.0   \n",
       "10558            0.0               1.0              0.0                0.0   \n",
       "10559            0.0               0.0              0.0                1.0   \n",
       "\n",
       "       Temperature  Humidity  Wind Speed  Precipitation (%)  \\\n",
       "0             26.0      45.0         3.5               10.0   \n",
       "1             29.0      71.0        21.0               86.0   \n",
       "2             38.0      63.0         5.5               11.0   \n",
       "3             17.0      66.0        18.0               63.0   \n",
       "4             32.0      39.0         7.5                3.0   \n",
       "...            ...       ...         ...                ...   \n",
       "10555        -19.0      27.0         5.5               66.0   \n",
       "10556         27.0      63.0         8.0               73.0   \n",
       "10557         25.0      23.0         4.5               13.0   \n",
       "10558         38.0      39.0         9.0               10.0   \n",
       "10559         11.0      61.0         9.5               41.0   \n",
       "\n",
       "       Atmospheric Pressure  UV Index  Visibility (km)  \n",
       "0                   1011.01       7.0              5.0  \n",
       "1                   1013.77      12.0              6.5  \n",
       "2                   1013.87      11.0              7.5  \n",
       "3                    992.22       1.0              2.5  \n",
       "4                   1021.43       9.0              5.5  \n",
       "...                     ...       ...              ...  \n",
       "10555                929.72       9.0             14.5  \n",
       "10556               1016.64       2.0              1.0  \n",
       "10557               1014.45      11.0              6.5  \n",
       "10558               1018.10      10.0              7.0  \n",
       "10559               1008.30       3.0              6.5  \n",
       "\n",
       "[10560 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to see what the encoded data set looks like\n",
    "\n",
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a80f0",
   "metadata": {},
   "source": [
    "**Question for you:** It appears that we applied the same One Hot Encoding transformation to both training and test set. Why did we bother doing this operation on the separate sets? Could have we just transformed the original dataframe `df`, and then split it in training and test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca55587",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> From the coding block above, we can see that we fit the encoder on the training data and transform at the same time by using the `ct.fit_transform()` function. If we have transformed the original dataframe, and then split it into training and testing sets, the encoder (classifier) may have seen the testing set when it transforms the original dataframe. However, we want the testing set to remain unseen to evaluate the model performance more accurately. Therefore, I think we should avoid transforming the original dataframe first.  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcfe025",
   "metadata": {},
   "source": [
    "There are many classifiers we can choose from. We will use [Decision Trees](https://scikit-learn.org/stable/modules/svm.html) to start. Decision trees are very simple classification algorithms, although they have typically mediocre performance on complex classification problems.\n",
    "\n",
    "A certain level of familiarity with Decision Trees is expected in this course. You may want to review the material from your previous courses, or this [introduction](https://www.youtube.com/watch?v=ZVR2Way4nwQ). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7d713bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\lcm57\\AppData\\Local\\Temp\\ipykernel_24896\\1328174913.py\", line 4, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\__init__.py\", line 129, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\ticker.py\", line 138, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\lcm57\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_tree\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier() \u001b[38;5;66;03m# Create a decision tree\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_encoded, y_train) \u001b[38;5;66;03m# Fit a decision tree\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\__init__.py:129\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\colors.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\ticker.py:138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    140\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    142\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    143\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    151\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsci430\\lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier() # Create a decision tree\n",
    "model.fit(X_train_encoded, y_train) # Fit a decision tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404049a",
   "metadata": {},
   "source": [
    "Now that we have the tree, we want to see how well it performs. Let's first check the accuracy on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05252e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train_encoded, y_train) # Score the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4344e6",
   "metadata": {},
   "source": [
    "**100% accuracy!!!**\n",
    "\n",
    "...\n",
    "\n",
    "This sounds too good to be true... let's check the test set to see how well the trees perform on unseen samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023977ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test_encoded, y_test) # Score the decision tree on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de26d80",
   "metadata": {},
   "source": [
    "Accuracy dropped significantly when we moved to unseen samples!\n",
    "\n",
    "This is because the Decision Tree, if left unsupervised, is very prone to **overfitting**. \n",
    "\n",
    "**Question for you:** what does it mean for a model to overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5f27c",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> The issue of overfitting occurs when the model fits on the training set too well. In other words, it might understand and follow the patterns of the training set to closely, but may perform poorly when it sees a new unseen dataset (e.g. testing set). The model is too specific for the training set, but not generalized enough for unseen data.  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b305fe8",
   "metadata": {},
   "source": [
    "To prevent a model from overfitting, we tune its **hyperparameters.** Hyperparameters are like knobs that we can use to regulate the way a model learn. \n",
    "\n",
    "Some hyperparameters for the scikit-learn DecisionTreeClassifier include:\n",
    "- max_depth: the maximum distance between the root node and a leaf node\n",
    "- min_samples_split: the minimum number of samples required to split an internal node\n",
    "- min_samples_leaf; the minimum number of samples required to be at a leaf node\n",
    "\n",
    "You can look up other hyperparameters and their default values in the DecisionTreeClassifier [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier). By default, the maximum depth value is set to *None*, that is, the tree is free to grow until it has parfectly classified all samples. As we have seen, this results in perfect accuracy on the training set, but much lower accuracy on unseen samples. \n",
    "\n",
    "Run the cell below to see the depth of our overfitted tree:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a045a20",
   "metadata": {},
   "source": [
    "If we could find the right depth for our tree, we could reduce the problem of overfitting.\n",
    "\n",
    "**Question for you:** what would happen if we reduce the depth of the tree *too much*? What do you expect the accuracy on training and test set to look like in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be21765a",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> If we reduce the depth of the tree too much, the model will not be able to learn enough information from the training set. The model will be too generalized and does not capture enough patterns from the features for prediction when training the model. I think in this case, both the training and testing sets will have very low accuracy. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b918627",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is typically done on a **validation set.** A validation set is a set of samples not used for training, like the test set, but unlike the test set, we are allowed to use this multiple times as we look for the best hyperparameter values.\n",
    "\n",
    "Because our data set is rather small, it is not great to take more samples from the training set to create a validation set, because:\n",
    "- We would have fewer samples (less information) to train our model\n",
    "- The validation set would also be small, and result in a highly variable accuracy measure (meaning if we run the experiment again changing the samples in each set, we will likely get very different results)\n",
    "\n",
    "There is a method that we can use to eliminate both problems, called ***k*-fold cross-validation.** Cross-validation iteratively separates training and validation set (*k* times), so we get multiple measures of accuracy on the validation sets, which can be averaged for a more stable result. A good understanding of how cross-validation works is important for any data scientist. I encourage you to review cross-validation from previous courses, or this [introduction video](https://www.youtube.com/watch?v=4cv8VYonepA) (courtesy of Dr. Kolhatkar).\n",
    "\n",
    "Scikit-learn has a great method that we can use to perform cross-validation and find the best hyperparameters for a model at the same time, called [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). Let's use it to find the best depth for our Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5e951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np  # to create the array of values for depth\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": np.arange(1, 20, 1)  # testing all depths from 1 to 19\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model, param_grid, cv=10, n_jobs=-1, return_train_score=True   # 10-fold cross-validation for all possible \n",
    "                                                                   # depths\n",
    ")\n",
    "grid_search.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4668c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82f4143",
   "metadata": {},
   "source": [
    "**Complete the sentence (replace --?--):** Among all possible trees, GridSearchCV picked a tree of depth **12**, with an average validation accuracy of **0.9108901515151514**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bc8999",
   "metadata": {},
   "source": [
    "The accuracy on the training set is no longer 100%, but we expect this tree to perform better on unseen samples. Let's try it on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "best_tree.score(X_test_encoded, y_test) # Score the decision tree on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83301822",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The accuracy is similar to when the model was overfitting, but hyperparameter tuning brought us 2 advantages:\n",
    "- We had a more realistic expectation of what our accuracy was going to be (closer to 91%, not 100%)\n",
    "- We simplified the model and reduced its depth. This makes the model faster and easier to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5209b3",
   "metadata": {},
   "source": [
    "**Question for you:** on what samples (or portion of samples) of `X_train_encoded` was the final model (`best_tree`) trained on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccdded8",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> I think all samples of `X_train_encoded` were used to train the final model. When we do the 10-fold cross-validation, each time we pick 9 folds as the training set and 1 fold as the validation set. We repeat this 10 times until all 10 folds have been used for validation, and the measures are \"averaged for a more stable result\". Therefore, the model sees the whole training set when it is trained.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccc9bf",
   "metadata": {},
   "source": [
    "The model can now be used to get predictions for unseen samples. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = X_test_encoded.sample(n=1, random_state=42)\n",
    "\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c18eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree.predict(random_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a95af",
   "metadata": {},
   "source": [
    "# Final thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadac478",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1) If you have completed this assignment in a group, please write a detailed description of how you divided the work and how you helped each other completing it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba472e70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5c81ffd",
   "metadata": {},
   "source": [
    "2) Have you used ChatGPT or a similar Large Language Model (LLM) to complete this homework? Please describe how you used the tool. **We will never deduct points for using LLMs for completing homework assignments,** but this helps us understand how you are using the tool and advise you in case we believe you are using it incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56fa1e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08a7bf06",
   "metadata": {},
   "source": [
    "3) Have you struggled with some parts (or all) of this homework? Do you have pending questions you would like to ask? Write them down here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b82cbc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsci430]",
   "language": "python",
   "name": "conda-env-dsci430-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
