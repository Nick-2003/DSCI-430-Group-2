{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee102f61",
   "metadata": {},
   "source": [
    "# Module 3 - Algorithm auditing: Accuracy, Fairness and Interpretability \n",
    "\n",
    "\n",
    "### Assignment overview\n",
    "\n",
    "In this assignment, you will be asked to evaluate a set of trained classifiers for accuracy, fairness and transparency. The classifiers have been trained on the [NIJ Recidivism Challenge Dataset](https://nij.ojp.gov/funding/recidivism-forecasting-challenge) to predict whether or not an individual will be arrested for a new crime within 3 years after being released on parole. \n",
    "\n",
    "The assignment is modeled after “Accuracy, Fairness, and Interpretability of Machine Learning Criminal Recidivism Models, by Eric Ingram, Furkan Gursoy, Ioannis A. Kakadiaris (https://arxiv.org/abs/2209.14237). \n",
    "\n",
    "For this assignment, it is possible to work in **groups of up to 2 students**. Read the instructions carefully, as they may assign tasks to specific students.\n",
    "\n",
    "### Group members\n",
    "Leave blanks if group has less than 2 members:\n",
    "- Student 1: Jingyuan Liu (S.N. 69763183)\n",
    "- Student 2: Nicholas Tam (S.N. 45695970)\n",
    "\n",
    "### Learning Goals:\n",
    "\n",
    "After completing this week's lecture and tutorial work, you will be able to:\n",
    "1. Describe different fairness metrics, such as statistical parity, equal opportunity and equal accuracy \n",
    "2. Discuss fairness and fairness metrics from the perspective of multiple stakeholders \n",
    "3. Define objective functions based on fairness metrics  \n",
    "4. Evaluate a model’s transparency using strategies such as global surrogate models, permutation feature importance, and Shapley Additive Explanations (SHAP) \n",
    "5. Evaluate common machine learning models based on their accuracy, fairness and interpretability \n",
    "6. Describe how metrics such as accuracy and fairness need to be balanced for a trained model to have acceptable accuracy and low bias "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca85f2",
   "metadata": {},
   "source": [
    "## Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3342b2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here are some libraries you may need for this exercise, for your convenience\n",
    "#!pip install scikit-learn==1.0.2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "# !pip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    plot_confusion_matrix, # Depreciated, use ConfusionMatrixDisplay\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "\n",
    "\n",
    "import joblib\n",
    "from sklearn import tree\n",
    "from sklearn.inspection import permutation_importance\n",
    "# !pip install eli5\n",
    "import eli5\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3af91b",
   "metadata": {},
   "source": [
    "# Part 1: Getting started:\n",
    "\n",
    "Before starting this assignment, we ask you to read the paper it has been modeled after, to get an idea of the problem we are working on: https://arxiv.org/abs/2209.14237\n",
    "\n",
    "You can also review the original dataset source [here](https://nij.ojp.gov/funding/recidivism-forecasting-challenge). The website includes a lot of information on the dataset and a detailed description of each of its columns (look for Appendix 2: Codebook).\n",
    "\n",
    "Now that you have familiarized with the problem, you know that the goal is predicting the binary variable `Recidivism_Within_3years`, which indicates whether or not the person has committed a new felony or misdemeanour within 3 years from the beginning of parole supervision. \n",
    "\n",
    "The National Institute of Justice’s (NIJ) obviously would want to deploy a highly accurate predictive model, to make sure that only deserving people get released on parole. Unfortunately, the existence of bias in the training set (typically historical or representation bias) makes it very likely to end up with an unfair classifier, that is, a classifier that produces different results for different protected classes of population.\n",
    "\n",
    "Your job is to evaluate 5 classifiers, pre-trained and provided to you. This is called **algorithm auditing:** you are not the designer of the model, but you are in charge of evaluating its performance. Algorithm auditing can focus on various metrics and populations of interest, but in this case we will focus on evaluating **accuracy, fairness and transparency** of each algorithm.\n",
    "\n",
    "To begin, load the datasets and classsifiers by running the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1894ff7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: these training and test sets do not correspond to the ones on the NIJ's website,\n",
    "# they are our own partition\n",
    "\n",
    "train_df = pd.read_csv(\"training_set.csv\")\n",
    "test_df = pd.read_csv(\"testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2cb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and test sets and separating features and target\n",
    "X_train, y_train = (\n",
    "    train_df.drop(columns=[\"Recidivism_Within_3years\"]),\n",
    "    train_df[\"Recidivism_Within_3years\"],\n",
    ")\n",
    "X_test, y_test = (\n",
    "    test_df.drop(columns=[\"Recidivism_Within_3years\"]),\n",
    "    test_df[\"Recidivism_Within_3years\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84edeb61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading classifiers\n",
    "logreg_model  = joblib.load(\"models_for_A3/NIJ_logreg.joblib\")\n",
    "rf_model      = joblib.load(\"models_for_A3/NIJ_rf.joblib\")\n",
    "tree_model    = joblib.load(\"models_for_A3/NIJ_tree.joblib\")\n",
    "xgboost_model = joblib.load(\"models_for_A3/NIJ_xgboost.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecefb9",
   "metadata": {},
   "source": [
    "# Part 2: Classifiers' Accuracy (and other performance metrics):\n",
    "\n",
    "First, we will evaluate each classifier's accuracy, together with other performance metrics that help us understanding how reliable the classifier's answers are. In addition to accuracy, we will use, **precision, recall, F1 score, and Area Under the Curve (AUC).**\n",
    "\n",
    "### Question 1\n",
    "\n",
    "can you provide definition and formula for accuracy, precision, recall and F1 score?\n",
    "\n",
    "It may help you use this table for reference:\n",
    "\n",
    "<img src=\"ConfMatrix.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Here, we are giving you the definition of AUC, as a reminder and example (note that the other metrics will need the formula):\n",
    "\n",
    "**AUC:** AUC stands for Area Under the ROC curve. The ROC (receiver operating characteristic) curve is a plot of the recall and false positive rate of a classifier for different classification thresholds (see [here](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc) for more details). AUC values go between 0 and 1. Higher values are more desirable as they indicate that the classifier is good at avoiding both false positives and false negatives. A value of 0.5 for a binary classification indicates that the classifier is no better at predicting the outcome than random guessing.\n",
    "\n",
    "**<span style=\"color:blue\">Add remaining definitions and formulas here</span>**\n",
    "* <span style=\"color:blue\">Accuracy: </span>\n",
    "* <span style=\"color:blue\">Precision: </span>\n",
    "* <span style=\"color:blue\">Recall: </span>\n",
    "* <span style=\"color:blue\">F1 score: </span>\n",
    "\n",
    "### Question 2\n",
    "\n",
    "For every classifier given, calculate and report accuracy, precision, recall, F1 score, and AUC on both training and test set. **For ease of visualization, summarize these results in one or two tables below this question.**\n",
    "\n",
    "**Hints:** \n",
    "- Scikit-learn provides a lot of useful built-in functions to compute performance metrics. You can find them all in the package [`sklearn.metrics`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics), under Classification Metrics.\n",
    "- Some classifiers may take longer than others to make their predictions, so you may have to wait a few minutes for a cell to run. More than that, however, likely means something is wrong and needs to be fixed before continuing.\n",
    "\n",
    "| Metric | Accuracy | Precision | Recall | F1-Score | AUC |\n",
    "| :------- | :------- | :------- | :------- | :------- | :------- |\n",
    "| LogReg | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> |\n",
    "| Random Forest | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> |\n",
    "| Decision Tree | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> |\n",
    "| XGBoost | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> | <ul><li><span style=\"color:blue\">Training: </span></li><li><span style=\"color:blue\">Testing: </span></li></ul> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4a652",
   "metadata": {},
   "source": [
    "### LogReg Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2bd48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute required metrics here. You may add more cells if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b32640",
   "metadata": {},
   "source": [
    "### Random Forest Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea538f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute required metrics here. You may add more cells if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1078f9",
   "metadata": {},
   "source": [
    "### Decision Tree Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37d6d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute required metrics here. You may add more cells if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c84c8",
   "metadata": {},
   "source": [
    "### XGBoost Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92cde1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute required metrics here. You may add more cells if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b92f6d4",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "For every classifier given, plot the confusion matrices on training and test set. Here is another function you will find helpful for this task: [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0056151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output confusion matrices here. You may add more cells if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d77281",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Based on the results obtained so far, answer the following questions, providing an explanation and trying to base your decision on multiple metrics:\n",
    "- Which classifiers would you choose for deployment?\n",
    "    - <span style=\"color:blue\">TEXT</span>\n",
    "- Which classifier is the most \"severe\" (a.k.a. classifies more people as at risk of committing another crime within 3 years)?\n",
    "    - <span style=\"color:blue\">TEXT</span>\n",
    "- Which classifier is the most cautious (a.k.a. classifies less people as at risk of committing another crime within 3 years)?\n",
    "    - <span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a86647",
   "metadata": {},
   "source": [
    "# Part 3 :  Fairness Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053779ec",
   "metadata": {},
   "source": [
    "Now that we have an understanding of how accurate our classifiers are across all samples, we need to measure their *fairness* across different categories. In similar problems, we are typically concerned with the classifiers being fair across different segments of protected populations (e.g. different genders or ethnicities). The original paper evaluates fairness for both gender and race, but for the purpose of this exercise we will only look at fairness across race, that is, for White and Black defendants.\n",
    "\n",
    "### Question 5\n",
    "\n",
    "As we have seen in class, there is not just one fairness metric, but several, as they have different ways to identify different treatments across populations. The metrics used in the paper, which you will have to replicate, are:\n",
    "\n",
    "1. *Predicted Positive Rate Disparity (PPRD)*, whether the numbers of positive predictions are on par across groups.\n",
    "2. *Predicted Positive Group Rate Disparity (PPGRD)*, whether the rates of positive predictions are on par across groups.\n",
    "3. *False Discovery Rate Disparity (FDRD)*, whether the ratios of false positives to predicted positives are on par across groups.\n",
    "4. *False Positive Rate Disparity (FPRD)*, whether the ratios of false positives to actual negatives are on par across groups.\n",
    "5. *False Omission Rate Disparity (FORD)*, whether the ratios of false negatives to predicted negatives are on par across groups.\n",
    "6. *False Negative Rate Disparity (FNRD)*, whether the ratios of false negatives to actual positives are on par across groups.\n",
    "\n",
    "Before jumping into code writing, we must make sure that we have a solid understanding of how these metrics are computed from the True Positive, True Negative, False Positive, and False Negative values *for each group*. We will add the subscript *b* and *w* when appropriate to identify metrics from the group of black or white defendants, respectively. Then, we will write the equations for all fairness metrics. The first one is provided to you as an example:\n",
    "\n",
    "| Metric    | Formula |\n",
    "| :-------- | :------- |\n",
    "| PPRD  |  (TPb + FPb) / (TPw + FPw)  |\n",
    "| PPGRD | <span style=\"color:blue\">TEXT</span> |\n",
    "| FDRD | <span style=\"color:blue\">TEXT</span> |\n",
    "| FPRD | <span style=\"color:blue\">TEXT</span> |\n",
    "| FORD | <span style=\"color:blue\">TEXT</span> |\n",
    "| FNRD | <span style=\"color:blue\">TEXT</span> |\n",
    "\n",
    "Finally, the paper also computes an **Average Distance from Reference** across all the above metrics. This helps us summarizing the fairness of a classifier in a single number. Compute the Average Distance from Reference for all the classifiers, knowing that the reference is 1 (i.e. a score of 1 indicates perfect fairness). Use tha absolute value to compute the distance from the reference (e.g. a FDRD score of 0.80 and one of 1.20 both have a distance from the reference of 0.20).\n",
    "\n",
    "Now that you have a better understanding of how to compute these metrics, do so for all the classifiers, both on the training and the test sets.\n",
    "\n",
    "**Hints:**\n",
    "- There are several ways to write Python code to easily compute the fairness metrics we want. If you have trouble starting, talk with a TA or with the instructor during our in-class work time or office hours to come up with a plan. \n",
    "- Instead of copy-pasting code, it is definitely a good idea to create one or more functions to compute the fairness metrics. Writing functions in Python is very easy! If you are new to it, start [here](https://www.geeksforgeeks.org/python-functions/) (stop before Arbitrary Keyword Arguments), and of course, come to us for more help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55662331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many cells as needed to compute the required metrics for every classifier. You may\n",
    "# also add markdown cells if you want to add comments or notes about your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c18009",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Based on the results obtained so far, answer the following questions, providing an explanation for each answer:\n",
    "- Which model exhibits the least amount of bias? \n",
    "- Which one is the worse?\n",
    "- Based on the application, which fairness metric(s) do you think should be the most important? Which one(s) could be taken less into consideration?\n",
    "- Finally, based on the fairness results, which model would you pick for this application? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738bfe11",
   "metadata": {},
   "source": [
    "# Part 4: Interpretability Evaluation:\n",
    "\n",
    "Finally, we will evaluate the *interpretability* of our models. It is important to be able to explain how the model uses each feature to make its predictions and *why* a model has given a particular response for an individual - especially important when, like in this case, people's lives are being affected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e8924",
   "metadata": {},
   "source": [
    "### Inherently Interpretable Models\n",
    "\n",
    "Some models are known to be *inherently interpretable*, meaning we can decifer the model behavior by looking at its parameters. These models are also called \"white-box\" models. Logistic regression models and decision trees - in some cases - fall in this category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e3b47e",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Run the cells below and look at the weights of the logistic regression model. For simplicity, the cells below show the 10 most positive and 10 most negative coefficients. What features bring the prediction more toward the positive class? What other features push the prediction toward the negative class? Do you see any coefficients that may be unfairly influencing the decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca4fac4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Estimator simpleimputer does not provide get_feature_names_out. Did you mean to call pipeline[:-1].get_feature_names_out()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mlogreg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumntransformer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m coeffs \u001b[38;5;241m=\u001b[39m logreg_model\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogisticregression\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      3\u001b[0m coeff_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(coeffs, index\u001b[38;5;241m=\u001b[39mfeature_names, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoefficient\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/dsci430/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:481\u001b[0m, in \u001b[0;36mColumnTransformer.get_feature_names_out\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m    479\u001b[0m transformer_with_feature_names_out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, trans, column, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(fitted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 481\u001b[0m     feature_names_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_feature_name_out_for_transformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_features\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsci430/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:454\u001b[0m, in \u001b[0;36mColumnTransformer._get_feature_name_out_for_transformer\u001b[0;34m(self, name, trans, column, feature_names_in)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(column, Iterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m column\n\u001b[1;32m    452\u001b[0m ):\n\u001b[1;32m    453\u001b[0m     column \u001b[38;5;241m=\u001b[39m _safe_indexing(feature_names_in, column)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsci430/lib/python3.10/site-packages/sklearn/pipeline.py:751\u001b[0m, in \u001b[0;36mPipeline.get_feature_names_out\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transform, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_feature_names_out\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 751\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    752\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m does not provide get_feature_names_out. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    753\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid you mean to call pipeline[:-1].get_feature_names_out\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    754\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m    755\u001b[0m         )\n\u001b[1;32m    756\u001b[0m     feature_names_out \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mget_feature_names_out(feature_names_out)\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_names_out\n",
      "\u001b[0;31mAttributeError\u001b[0m: Estimator simpleimputer does not provide get_feature_names_out. Did you mean to call pipeline[:-1].get_feature_names_out()?"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(logreg_model.named_steps['columntransformer'].get_feature_names_out())\n",
    "coeffs = logreg_model.named_steps[\"logisticregression\"].coef_.flatten()\n",
    "coeff_df = pd.DataFrame(coeffs, index=feature_names, columns=[\"Coefficient\"])\n",
    "coeff_df_sorted = coeff_df.sort_values(by=\"Coefficient\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df_sorted.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb62b22c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c47590ed",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Now, let's look at a particular sample and try to explain its prediction. We have picked this sample because its feature values make it a hard case, one very close to the threshold between positive and negative class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb79984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_sample = X_test[106:107]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3122999",
   "metadata": {},
   "source": [
    "If you look at the ground truth for this sample (try `y_test[106:107]`) you will see that this person has not, in fact, committed a new crime within 3 years from release. But what is the prediction of the logistic regression model? Find the answer and comment below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6baf318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c190d5d7",
   "metadata": {},
   "source": [
    "Take a closer look at the feature values for this sample. What seems to have contributed the most to the final prediction? What feature pushed the most in the opposite direction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f60cfc",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f682f5a",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "We said that decision trees are also inherently interpretable - *potentially*. That is because, in theory, it is possible to look at the tree structure and to follow the path along the tree to see how each node influenced the decision. But this is only possible if the tree has a reasonably small size.\n",
    "\n",
    "Run the cell below and see if you can tell what are the most influencial features in the decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(tree_model[\"dt\"],fontsize=10)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3de87e",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b43ae1",
   "metadata": {},
   "source": [
    "If the method above was not satisfactory, you can try visualizing all the rules of the decision tree as text. Is this any better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10999cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "tree_rules = export_text(tree_model.named_steps['dt'], feature_names=list(tree_model.named_steps['ct'].get_feature_names_out()))\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8f671",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a8d46",
   "metadata": {},
   "source": [
    "When it is not possible to interpret a decision tree because of its complex structure, we can still extract other information from it that will help us understand the features' importance in the decision. The code in the cell below extracts the feature importances from the model (line 3), then uses this information to create a bar plot of features sorted by importance. The feature importance extracted this way is based on [Gini Importance](https://www.codecademy.com/article/fe-feature-importance-final) (as it is done in the original paper), which reflects how the features were picked when building the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e891206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "feature_importances = tree_model.named_steps[\"dt\"].feature_importances_\n",
    "\n",
    "# Sort the feature importances from greatest to least using the sorted indices\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "sorted_feature_names = tree_model.named_steps['ct'].get_feature_names_out()[sorted_indices]\n",
    "sorted_importances = feature_importances[sorted_indices]\n",
    "\n",
    "# # Create a bar plot of the feature importances\n",
    "sns.set(rc={'figure.figsize':(11.7,30)})\n",
    "sns.barplot(x=sorted_importances, y=sorted_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc53165",
   "metadata": {},
   "source": [
    "Comment on the features importance of the tree model, compared to those seen in the logistic regression model, as well as the original paper results. Also, **what is a big limitation of using feature importance, compared to observing the coefficient of the logistic regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af139a53",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365cd708",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "As before, we are interested in evaluating how the model classifies a particular sample. Let's start looking at the classification for our `hard_sample`. Is it correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81084c12",
   "metadata": {},
   "source": [
    "We would like to be able to tell what sequence of rules has led to this final decision, but, for a tree this large, this can be difficult, unless we want to manually sift through the list of rules or write some elaborate custom code. In the next sections, we will see an alternative method (SHAP) to achieve this result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7aafa",
   "metadata": {},
   "source": [
    "### Question 11: Evaluation of Non-inherently Interpretable Models Using a Surrogate Model\n",
    "\n",
    "Models that are not inherently interpretable (\"black box\" models) can still be examined to understand how they used the available features to make their predictions. In fact, there are many strategies to do this. The first one we are going to see is through use of a **surrogate model.** In this case, we train another model - an inherently interpretable one, such as a logistic regressor - on the *predictions* of the black box model, and then we try to interpret *its parameters*. Let's complete the code below to do that on the two non-inherently interpretable models included in this exercise: the Random Forest and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f75190",
   "metadata": {},
   "source": [
    "#### Surrogate for Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e2dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: create logistic regressor object.\n",
    "# For simplicity, we will use the already existing \"NIJ_logreg.joblib\" and re-train it, instead of creating\n",
    "# a new one. The reason for this decision is that NIJ_logreg.joblib already knows how to handle the features\n",
    "# of this dataset, while a new one will need to be designed to do so.\n",
    "\n",
    "# surrogate_model_rf = joblib.load(\"NIJ_logreg.joblib\")\n",
    "surrogate_model_rf = joblib.load(\"models_for_A3/NIJ_logreg.joblib\")\n",
    "\n",
    "# Step 2: train model on random forest predictions on the training set\n",
    "\n",
    "# Step 3: visualize weights of surrogate model, as we did for the original logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c4466b",
   "metadata": {},
   "source": [
    "Now that we have the weights of the surrogate model, what can we say about how the Random Forest model makes its predictions? What features seem more important? Are they similar to what we have seen for the other models so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0e6991",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f49878",
   "metadata": {},
   "source": [
    "**Note:** using a surrogate model is not always a very good strategy, because the simpler \"white box\" model is often unable to replicate the behavior of the most complex \"black box\" model. We can get a sense of how close the surrogate is approximating the original model by looking at the R<sup>2</sup> score. In the paper, they do so when trying to create a surrogate for XGBoost, and they explain: \n",
    "\n",
    "*The R<sup>2</sup> value between the XGBoost predictions and the surrogate model predictions on the test set is 0.38. The surrogate model only explains 38% of the variance in the XGBoost model’s predictions*\n",
    "\n",
    "Test this for the random forest surrogate model. How much variance is it able to capture?\n",
    "\n",
    "**Hints:**\n",
    "- Think carefully about what constitues the array of predictions and the array of ground truths in this case\n",
    "- You may remember that R<sup>2</sup> is, in fact, a metric for regression, not for classification! How can we use R<sup>2</sup> in this case? There are various ways to approximate R<sup>2</sup> for classification, as explained [here](https://datascience.oneoffcoder.com/psuedo-r-squared-logistic-regression.html). We will use the simplest one and use **count R<sup>2</sup>**, which is simply the accuracy of the surrogate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a93b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66187d5d",
   "metadata": {},
   "source": [
    "Now, repeat the analysis through surrogate model for XGBoost. Comment on the results, including considerations on the following:\n",
    "- What seem to be the most important features?\n",
    "- How do the sets of most important features compare across models (do not forget logistic regression and decision tree in this comparison)?\n",
    "- How good are the surrogate models, in terms of capturing the variance of the original model? Are they reliable?\n",
    "- ...more thoughts of your choice..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7018704b",
   "metadata": {},
   "source": [
    "#### Surrogate for XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d49d08",
   "metadata": {},
   "source": [
    "### Question 12: Evaluation of Non-inherently Interpretable Models Using Permutation Feature Importance\n",
    "\n",
    "Another method used to interpret black box models is using feature permutation, which means changing the value of a feature and observing changes in the model's prediction error. More important features, when changed, will result in more frequent mistakes.\n",
    "\n",
    "Luckily for us, Permutation Feature Importance already exists as a function in Scikit-Learn! All you have to do it is looking at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html) to learn how it works, and apply it to the 3 non-inherently interpretable models of this exercise. Let's start with Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2319f8a",
   "metadata": {},
   "source": [
    "#### Random Forest Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use permutation_importance on the random forest model, and save the result in a variable called \"out\"\n",
    "out = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5043522",
   "metadata": {},
   "source": [
    "After you are done, you can run the cell below to visualize the top 5 most important features in a bar chart. If you like, you can change the number of features shown or try other visualization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d095579",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m: X_test\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mout\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportances_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTD\u001b[39m\u001b[38;5;124m\"\u001b[39m: out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportances_std\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n\u001b[1;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mset(rc\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m11.7\u001b[39m,\u001b[38;5;241m7\u001b[39m)})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame({\"Name\": X_test.columns, \"Importance\": out[\"importances_mean\"], \"STD\": out[\"importances_std\"]})\n",
    "result = result.sort_values(by=['Importance'], ascending=False)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,7)})\n",
    "sns.barplot(data=result[:5], y=\"Name\", x=\"Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa9d82",
   "metadata": {},
   "source": [
    "Now, use Permutation Feature Importance on XGBoost.\n",
    "\n",
    "**Hint:** this is a more complex model; if you find that this task is taking too long, you may consider reducing the number of permutations using the parameter `n_repeats`. Be aware that this produces more variable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251b843",
   "metadata": {},
   "source": [
    "#### XGBoost Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e60068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd8ee71e",
   "metadata": {},
   "source": [
    "Now that you have completed your analysis of feature importance using permutation, comment on the results. How do the sets of most important features compare with each other? Are this results similar to what you observed using the surrogate model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabe44e",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6adf64f",
   "metadata": {},
   "source": [
    "### Question 13: Evaluation of Non-inherently Interpretable Models Using SHAP\n",
    "\n",
    "The last method we are going to use to interpret the impact of each feature in our model is called SHAP, which stands for SHapley Additive exPlanations. How SHAP works is beyond the scope of this course, but if you are curious you can read the [original paper](https://arxiv.org/pdf/1705.07874.pdf) by Lundberg and Lee and check out [Lundberg's GitHub repo](https://github.com/shap/shap), which provides details on the implementation and examples.\n",
    "\n",
    "You will need to install SHAP to be able to use it:\n",
    "```\n",
    "pip install shap\n",
    "or\n",
    "conda install -c conda-forge shap\n",
    "```\n",
    "\n",
    "Then, import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5db2b9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.46.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy in /Users/student/miniconda3/lib/python3.12/site-packages (from shap) (2.1.1)\n",
      "Requirement already satisfied: scipy in /Users/student/miniconda3/lib/python3.12/site-packages (from shap) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/student/miniconda3/lib/python3.12/site-packages (from shap) (1.5.2)\n",
      "Requirement already satisfied: pandas in /Users/student/miniconda3/lib/python3.12/site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/student/miniconda3/lib/python3.12/site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in /Users/student/miniconda3/lib/python3.12/site-packages (from shap) (24.1)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting numba (from shap)\n",
      "  Downloading numba-0.60.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting cloudpickle (from shap)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->shap)\n",
      "  Downloading llvmlite-0.43.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting numpy (from shap)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/student/miniconda3/lib/python3.12/site-packages (from pandas->shap) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/student/miniconda3/lib/python3.12/site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/student/miniconda3/lib/python3.12/site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/student/miniconda3/lib/python3.12/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/student/miniconda3/lib/python3.12/site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/student/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.46.0-cp312-cp312-macosx_11_0_arm64.whl (455 kB)\n",
      "Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading numba-0.60.0-cp312-cp312-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp312-cp312-macosx_14_0_arm64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp312-cp312-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: slicer, numpy, llvmlite, cloudpickle, numba, shap\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "Successfully installed cloudpickle-3.0.0 llvmlite-0.43.0 numba-0.60.0 numpy-2.0.2 shap-0.46.0 slicer-0.0.8\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install shap\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m \u001b[38;5;66;03m# downgrade numpy to version = 1.23\u001b[39;00m\n\u001b[1;32m      3\u001b[0m shap\u001b[38;5;241m.\u001b[39minitjs()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "# !pip install shap\n",
    "import shap # downgrade numpy to version = 1.23\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ed15e",
   "metadata": {},
   "source": [
    "SHAP needs the model (we will start with Random Forest) and samples to use to explain the predictions. For this, we will need to give it transformed samples (scaled and imputed, as required by the model) from  `X_train` or `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc = pd.DataFrame(\n",
    "    data=rf_model.named_steps['ct'].transform(X_train),\n",
    "    columns=feature_names,\n",
    "    index=X_train.index,\n",
    ")\n",
    "\n",
    "X_test_enc = pd.DataFrame(\n",
    "    data=rf_model.named_steps['ct'].transform(X_test),\n",
    "    columns=feature_names,\n",
    "    index=X_test.index,\n",
    ")\n",
    "\n",
    "ind = np.random.choice(len(X_test_enc) - 1, 1000)  \n",
    "# This line just gives 1000 random indexes from the training set\n",
    "# We do this because getting SHAP values for all samples would be a bit too long, but you \n",
    "# are free to try it out!\n",
    "\n",
    "ind = np.append(ind, 106) # adding the hard sample - we'll need this later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca462e0",
   "metadata": {},
   "source": [
    "The following lines are all that's needed to explain the model's predictions for a set of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700995e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_explainer = shap.Explainer(rf_model[-1])  # creating SHAP Explainer based on the model\n",
    "\n",
    "rf_shap_values = rf_explainer.shap_values(X_test_enc.iloc[ind])  # explaining predictions for 1000 random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd145e6e",
   "metadata": {},
   "source": [
    "This gives us the SHAP values for each sample and each feature (the index 1 indicates the positive class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50319f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_shap_values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19468e",
   "metadata": {},
   "source": [
    "This is hardly interpretable, though. It is better to get the average values for each feature, which returns something similar to feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ca06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.abs(rf_shap_values[1]).mean(0)\n",
    "pd.DataFrame(data=values, index=feature_names, columns=[\"SHAP\"]).sort_values(\n",
    "    by=\"SHAP\", ascending=False\n",
    ")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8ce05",
   "metadata": {},
   "source": [
    "The SHAP library also has a lot of ways to visualize and interpret the SHAP values - try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437837c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_figure = shap.summary_plot(rf_shap_values[1], X_test_enc.iloc[ind], plot_size=[12,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239fb4c",
   "metadata": {},
   "source": [
    "Given the new information obtained using the SHAP library on the Random Forest model, explain the results (you will need to refer to the SHAP documentation - or ask us for help interpreting the plots) and comment on the difference between these results and those obtained using the other methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7676541",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2515f7b7",
   "metadata": {},
   "source": [
    "\n",
    "Next, **repeat this analysis for XGBoost.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873368fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34d613",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9b605",
   "metadata": {},
   "source": [
    "### Question 14: Explaining individual predictions using SHAP\n",
    "\n",
    "Another powerful feature of SHAP is that it allows us to explain the impact of each feature on individual predictions. For example, we will be able to explain how the prediction for our hard sample was generated. Let's start by looking at the prediction for this sample given by the random forest model. **Is it correct?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b800ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc330140",
   "metadata": {},
   "source": [
    "Let's look at the **force plot** for this particular prediction, by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    rf_explainer.expected_value[1],\n",
    "    rf_shap_values[1][-1],\n",
    "    X_test_enc.iloc[ind[-1]],\n",
    "    matplotlib=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97854e5f",
   "metadata": {},
   "source": [
    "**Interpret the plot results,**, including the following:\n",
    "- What contributed the most to the prediction?\n",
    "- What countered the prediction the most?\n",
    "- Can we tell, by looking at the plot, that this was a difficult prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc6716",
   "metadata": {},
   "source": [
    "* <span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63bed63",
   "metadata": {},
   "source": [
    "Finally, **repeat the analysis and comment on the results of the individual predictions made on the hard sample by XGBoost and Decision Tree** (since we were not able to do the latter earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1658142",
   "metadata": {},
   "source": [
    "* <span style=\"color:blue\">TEXT</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f813a",
   "metadata": {},
   "source": [
    "# Part 5: Final Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a3c2b9",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "\n",
    "Using **all the results collected so far** on accuracy, fairness and transparency of the 5 models, write your recommendation about what model, in your opinion, should be employed for this application (300 words max)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c12ede",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71f4a6b",
   "metadata": {},
   "source": [
    "# Final thoughts\n",
    "\n",
    "1) If you have completed this assignment in a group, please write a detailed description of how you divided the work and how you helped each other completing it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91004459",
   "metadata": {},
   "source": [
    "* <span style=\"color:blue\">Jingyuan's response: </span>\n",
    "* <span style=\"color:blue\">Nicholas' response: </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8fe51",
   "metadata": {},
   "source": [
    "2) Have you used ChatGPT or a similar Large Language Model (LLM) to complete this homework? Please describe how you used the tool. We will never deduct points for using LLMs for completing homework assignments, but this helps us understand how you are using the tool and advise you in case we believe you are using it incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012265f",
   "metadata": {},
   "source": [
    "* <span style=\"color:blue\">Jingyuan's response: </span>\n",
    "* <span style=\"color:blue\">Nicholas' response: </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c08f2f",
   "metadata": {},
   "source": [
    "3) Have you struggled with some parts (or all) of this homework? Do you have pending questions you would like to ask? Write them down here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc52a4",
   "metadata": {},
   "source": [
    "* <span style=\"color:blue\">Jingyuan's response: </span>\n",
    "* <span style=\"color:blue\">Nicholas' response: </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSCI 430",
   "language": "python",
   "name": "dsci430"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
